{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d8e6ba-0056-403a-89fa-4505bec17308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "### import from our files\n",
    "from mliv.dgps import get_data, get_tau_fn, fn_dict\n",
    "from mliv.neuralnet.utilities import log_metrics, plot_results, hyperparam_grid,\\\n",
    "                                     hyperparam_mult_grid, eval_performance\n",
    "from mliv.neuralnet.mnist_dgps import AbstractMNISTxz\n",
    "from mliv.neuralnet import AGMM,KernelLayerMMDGMM\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc8cb955-cbb6-4ec4-ad7c-d0683beca98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Z_agmm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Z_agmm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = x.squeeze()  # F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CNN_Z_kernel(nn.Module):\n",
    "    def __init__(self, g_features=100):\n",
    "        super(CNN_Z_kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, g_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0394ae1-bae3-46ed-a0ac-34ca26a87a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_z_kernel(n_z, n_hidden, g_features, dropout_p):\n",
    "    FC_Z_kernel = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, g_features),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return FC_Z_kernel\n",
    "\n",
    "\n",
    "def fc_z_agmm(n_z, n_hidden, dropout_p):\n",
    "    FC_Z_agmm = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_Z_agmm\n",
    "\n",
    "\n",
    "def fc_x(n_t, n_hidden, dropout_p):\n",
    "    FC_X = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_t, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58b6bc9b-1013-4bba-b673-bfe1bc05fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=False,\n",
    "    tau_fn=\"abs\",\n",
    "    n_samples=10000,\n",
    "    n_instruments=2,\n",
    "    iv_strength=0.5,\n",
    "    device=None,\n",
    "):\n",
    "    mnist_dgp = AbstractMNISTxz(X_IMAGE, Z_IMAGE, tau_fn)\n",
    "    n_test = n_samples // 10\n",
    "    n_t = 1\n",
    "\n",
    "    T, Z, Y, G, _ = mnist_dgp.generate_data(\n",
    "        n_samples, tau_fn=tau_fn, n_instruments=n_instruments, iv_strength=iv_strength\n",
    "    )\n",
    "\n",
    "    T_test, Z_test, Y_test, G_test, _ = mnist_dgp.generate_data(\n",
    "        n_test, tau_fn=tau_fn, n_instruments=n_instruments, iv_strength=iv_strength,\n",
    "    )\n",
    "\n",
    "    Z_train, Z_val, T_train, T_val, Y_train, Y_val, G_train, G_val = train_test_split(\n",
    "        Z, T, Y, G, test_size=0.1, shuffle=True\n",
    "    )\n",
    "    Z_train, T_train, Y_train, G_train = map(\n",
    "        lambda x: torch.Tensor(x), (Z_train, T_train, Y_train, G_train)\n",
    "    )\n",
    "    Z_val, T_val, Y_val, G_val = map(\n",
    "        lambda x: torch.Tensor(x).to(device), (Z_val, T_val, Y_val, G_val)\n",
    "    )\n",
    "    Z_test, T_test, Y_test, G_test = map(\n",
    "        lambda x: torch.Tensor(x).to(device), (Z_test, T_test, Y_test, G_test)\n",
    "    )\n",
    "\n",
    "    data_array = []\n",
    "    data_array.append((Z_train, T_train, Y_train, G_train))\n",
    "    data_array.append((Z_val, T_val, Y_val, G_val))\n",
    "    data_array.append((Z_test, T_test, Y_test, G_test))\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8e1fa31-07f0-4ab8-ab35-bcbf612cac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=False,\n",
    "    n_t=1,\n",
    "    n_instruments=2,\n",
    "    n_hidden=200,\n",
    "    dropout_p=0.1,\n",
    "    learner_lr=1e-4,\n",
    "    adversary_lr=1e-4,\n",
    "    learner_l2=1e-4,\n",
    "    adversary_l2=1e-4,\n",
    "    adversary_norm_reg=1e-4,\n",
    "    n_epochs=100,\n",
    "    batch_size=100,\n",
    "    train_learner_every=1,\n",
    "    train_adversary_every=1,\n",
    "):\n",
    "    if X_IMAGE:\n",
    "        learner = CNN_X()\n",
    "    else:\n",
    "        learner = fc_x(n_t, n_hidden, dropout_p)\n",
    "    if Z_IMAGE:\n",
    "        adversary = CNN_Z_agmm()\n",
    "    else:\n",
    "        adversary = fc_z_agmm(n_instruments, n_hidden, dropout_p)\n",
    "\n",
    "    def logger(learner, adversary, epoch, writer):\n",
    "        if not X_IMAGE:\n",
    "            writer.add_histogram(\"learner\", learner[-1].weight, epoch)\n",
    "        if not Z_IMAGE:\n",
    "            writer.add_histogram(\"adversary\", adversary[-1].weight, epoch)\n",
    "        log_metrics(\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            T_test,\n",
    "            learner,\n",
    "            adversary,\n",
    "            epoch,\n",
    "            writer,\n",
    "            true_of_T=G_val,\n",
    "        )\n",
    "\n",
    "    np.random.seed(12356)\n",
    "    print(\"---Hyperparameters---\")\n",
    "    print(\"Learner Learning Rate:\", learner_lr)\n",
    "    print(\"Adversary learning rate:\", adversary_lr)\n",
    "    print(\"Learner_l2:\", learner_l2)\n",
    "    print(\"Adversary_l2:\", adversary_l2)\n",
    "    print(\"Number of epochs:\", n_epochs)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    agmm = AGMM(learner, adversary).fit(\n",
    "        Z_train,\n",
    "        T_train,\n",
    "        Y_train,\n",
    "        learner_lr=learner_lr,\n",
    "        adversary_lr=adversary_lr,\n",
    "        learner_l2=learner_l2,\n",
    "        adversary_l2=adversary_l2,\n",
    "        n_epochs=n_epochs,\n",
    "        bs=batch_size,\n",
    "        logger=logger,\n",
    "        model_dir=\"agmm_model\",\n",
    "        device=device,\n",
    "        train_learner_every=train_learner_every,\n",
    "        train_adversary_every=train_adversary_every,\n",
    "    )\n",
    "\n",
    "    return agmm\n",
    "\n",
    "\n",
    "#### Train KernelLayerGMM\n",
    "def train_kernellayergmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    g_features=100,\n",
    "    kernel_fn=gaussian,\n",
    "    centers=None,\n",
    "    sigmas=None,\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=False,\n",
    "    n_t=1,\n",
    "    n_instruments=2,\n",
    "    n_hidden=200,\n",
    "    dropout_p=0.1,\n",
    "    learner_lr=1e-4,\n",
    "    adversary_lr=1e-4,\n",
    "    learner_l2=1e-4,\n",
    "    adversary_l2=1e-4,\n",
    "    adversary_norm_reg=1e-4,\n",
    "    n_epochs=100,\n",
    "    batch_size=100,\n",
    "    train_learner_every=1,\n",
    "    train_adversary_every=1,\n",
    "):\n",
    "    if X_IMAGE:\n",
    "        learner = CNN_X()\n",
    "    else:\n",
    "        learner = fc_x(n_t, n_hidden, dropout_p)\n",
    "    if Z_IMAGE:\n",
    "        adversary = CNN_Z()\n",
    "    else:\n",
    "        adversary = fc_z_kernel(n_instruments, n_hidden, g_features, dropout_p)\n",
    "\n",
    "    def logger(learner, adversary, epoch, writer):\n",
    "        if not X_IMAGE:\n",
    "            writer.add_histogram(\"learner\", learner[-1].weight, epoch)\n",
    "        # if not Z_IMAGE:\n",
    "        #  writer.add_histogram('adversary', adversary[-1].weight, epoch)\n",
    "        writer.add_histogram(\"adversary\", adversary.beta.weight, epoch)\n",
    "        log_metrics(\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            T_test,\n",
    "            learner,\n",
    "            adversary,\n",
    "            epoch,\n",
    "            writer,\n",
    "            true_of_T=G_val,\n",
    "        )\n",
    "\n",
    "    np.random.seed(12356)\n",
    "    print(\"---Hyperparameters---\")\n",
    "    print(\"Learner Learning Rate:\", learner_lr)\n",
    "    print(\"Adversary learning rate:\", adversary_lr)\n",
    "    print(\"Learner_l2:\", learner_l2)\n",
    "    print(\"Adversary_l2:\", adversary_l2)\n",
    "    print(\"Number of epochs:\", n_epochs)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"G features\", g_features)\n",
    "    print(\"Number of centers\", n_centers)\n",
    "    print(\"Kernel function\", kernel_fn.__name__)\n",
    "    klayermmdgmm = KernelLayerMMDGMM(\n",
    "        learner,\n",
    "        adversary,\n",
    "        g_features,\n",
    "        n_centers,\n",
    "        kernel_fn,\n",
    "        centers=centers,\n",
    "        sigmas=sigmas,\n",
    "    )\n",
    "    klayermmdgmm.fit(\n",
    "        Z_train,\n",
    "        T_train,\n",
    "        Y_train,\n",
    "        learner_l2=learner_l2,\n",
    "        adversary_l2=adversary_l2,\n",
    "        adversary_norm_reg=adversary_norm_reg,\n",
    "        learner_lr=learner_lr,\n",
    "        adversary_lr=adversary_lr,\n",
    "        n_epochs=n_epochs,\n",
    "        bs=bs,\n",
    "        logger=logger,\n",
    "        model_dir=\"klayer_model\",\n",
    "        device=device,\n",
    "        train_learner_every=train_learner_every,\n",
    "        train_adversary_every=train_adversary_every,\n",
    "    )\n",
    "\n",
    "    return klayermmdgmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06916d28-3b70-4797-9c7a-e0e5ee7edd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4add81c-a616-431a-a524-bc0cb957109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IMAGE = True\n",
    "Z_IMAGE = True\n",
    "tau_fn = \"abs\"\n",
    "n_samples = 1000\n",
    "n_instruments = 2\n",
    "iv_strength = 0.5\n",
    "data = generate_data(\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    tau_fn=tau_fn,\n",
    "    n_samples=n_samples,\n",
    "    n_instruments=n_instruments,\n",
    "    iv_strength=iv_strength,\n",
    "    device=device,\n",
    ")\n",
    "(Z_train, T_train, Y_train, G_train) = data[0]\n",
    "(Z_val, T_val, Y_val, G_val) = data[1]\n",
    "(Z_test, T_test, Y_test, G_test) = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b05735a7-31f0-445e-bb7d-5ffc5715282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20708bb9-a463-44d1-b015-b9f0af66859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
      "         Dropout2d-3           [-1, 64, 12, 12]               0\n",
      "            Linear-4                  [-1, 128]       1,179,776\n",
      "         Dropout2d-5                  [-1, 128]               0\n",
      "            Linear-6                    [-1, 1]             129\n",
      "================================================================\n",
      "Total params: 1,198,721\n",
      "Trainable params: 1,198,721\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.52\n",
      "Params size (MB): 4.57\n",
      "Estimated Total Size (MB): 5.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CNN_X().to(device), (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc8161f5-5b36-4faa-b2c2-f74f5d8ed627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Hyperparameters---\n",
      "Learner Learning Rate: 0.0001\n",
      "Adversary learning rate: 0.0001\n",
      "Learner_l2: 0.0001\n",
      "Adversary_l2: 0.0001\n",
      "Number of epochs: 10\n",
      "Batch Size: 100\n",
      "CPU times: user 866 ms, sys: 97.6 ms, total: 964 ms\n",
      "Wall time: 8.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parameters for networks\n",
    "dropout_p = 0.1\n",
    "n_t = 1\n",
    "n_hidden = 200\n",
    "\n",
    "# local hyperparam\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 10\n",
    "bs = 100\n",
    "agmm = train_agmm(Z_train, T_train, Y_train, G_train, Z_val, T_val, Y_val, G_val, T_test, G_test,\n",
    "                  X_IMAGE=True, Z_IMAGE=True, n_t=n_t, n_instruments=n_instruments,\n",
    "                  n_hidden=n_hidden, dropout_p=dropout_p, learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                  learner_l2=learner_l2, adversary_l2=adversary_l2, adversary_norm_reg=adversary_norm_reg,\n",
    "                  n_epochs=n_epochs, batch_size=bs)\n",
    "\n",
    "\n",
    "#plot_results(agmm, T_test, true_of_T_test=G_test)\n",
    "#eval_performance(agmm,T_test, true_of_T_test=G_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
